{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import utils\n",
    "import jieba\n",
    "import numpy as np\n",
    "from typing import *\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "class Classifier:\n",
    "    def __init__(self, model_dir: str):\n",
    "        # 注意CountVectorizer的参数应与训练时一致\n",
    "        vocab, self.p_c, self.p_w_c, self.labels = utils.load_model(model_dir)\n",
    "        self.cv = CountVectorizer(analyzer=\"word\", token_pattern=r\"(?u)\\b\\w+\\b\", vocabulary=vocab)\n",
    "\n",
    "    def predict_text(self, text: str, top_n: int=1) -> List[Tuple[str, float]]:\n",
    "        \"\"\"\n",
    "        单条预测接口\n",
    "        :param text: 待分类文本\n",
    "        :param top_n: 返回三个预测结果\n",
    "        :return: [(category_name, probability)]\n",
    "        \"\"\"\n",
    "        seg = \" \".join(utils.jieba_segment(text, mode=\"search\"))\n",
    "        text_vec = self.cv.transform([seg])\n",
    "        log_p_d_c = text_vec @ np.log(self.p_w_c)\n",
    "        log_p_c_d = np.log(self.p_c).reshape(-1, 1) + log_p_d_c.T\n",
    "        prob = utils.softmax(log_p_c_d)\n",
    "        top_n_index = prob[:, 0].argsort()[::-1][:top_n]\n",
    "        # return [(self.labels[index], prob[:, 0][index]) for index in top_n_index]\n",
    "        return [(self.labels[index]) for index in top_n_index]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def preprocess_prediction_data(data):\n",
    "    examples = []\n",
    "    for text_a in data:\n",
    "        examples.append({\"text_a\": text_a})\n",
    "    return examples"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# test = pd.read_table('resources/cropus/iphone13_comment.txt', sep='\\t',header=None)\n",
    "# test.columns = [\"text_a\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# 对测试集数据进行格式处理\n",
    "data1 = list(test.text_a)\n",
    "examples = preprocess_prediction_data(data1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "jieba: the input parameter should be unicode.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [13], line 4\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28mcls\u001B[39m \u001B[38;5;241m=\u001B[39m Classifier(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mresources/model/classification_model\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m examples:\n\u001B[0;32m----> 4\u001B[0m     res \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mcls\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict_text\u001B[49m\u001B[43m(\u001B[49m\u001B[43mi\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtop_n\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m3\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      5\u001B[0m     \u001B[38;5;28mprint\u001B[39m(res)\n",
      "Cell \u001B[0;32mIn [10], line 14\u001B[0m, in \u001B[0;36mClassifier.predict_text\u001B[0;34m(self, text, top_n)\u001B[0m\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpredict_text\u001B[39m(\u001B[38;5;28mself\u001B[39m, text: \u001B[38;5;28mstr\u001B[39m, top_n: \u001B[38;5;28mint\u001B[39m\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m List[Tuple[\u001B[38;5;28mstr\u001B[39m, \u001B[38;5;28mfloat\u001B[39m]]:\n\u001B[1;32m      8\u001B[0m     \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m      9\u001B[0m \u001B[38;5;124;03m    单条预测接口\u001B[39;00m\n\u001B[1;32m     10\u001B[0m \u001B[38;5;124;03m    :param text: 待分类文本\u001B[39;00m\n\u001B[1;32m     11\u001B[0m \u001B[38;5;124;03m    :param top_n: 返回三个预测结果\u001B[39;00m\n\u001B[1;32m     12\u001B[0m \u001B[38;5;124;03m    :return: [(category_name, probability)]\u001B[39;00m\n\u001B[1;32m     13\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m---> 14\u001B[0m     seg \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(\u001B[43mutils\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjieba_segment\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtext\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmode\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43msearch\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m)\n\u001B[1;32m     15\u001B[0m     text_vec \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcv\u001B[38;5;241m.\u001B[39mtransform([seg])\n\u001B[1;32m     16\u001B[0m     log_p_d_c \u001B[38;5;241m=\u001B[39m text_vec \u001B[38;5;241m@\u001B[39m np\u001B[38;5;241m.\u001B[39mlog(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mp_w_c)\n",
      "File \u001B[0;32m~/Desktop/UnsupervisedTextClassification-master/utils.py:70\u001B[0m, in \u001B[0;36mjieba_segment\u001B[0;34m(text, mode)\u001B[0m\n\u001B[1;32m     69\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mjieba_segment\u001B[39m(text: \u001B[38;5;28mstr\u001B[39m, mode: \u001B[38;5;28mstr\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m List[\u001B[38;5;28mstr\u001B[39m]:\n\u001B[0;32m---> 70\u001B[0m     seg \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mjieba\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtokenize\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtext\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmode\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmode\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     71\u001B[0m     \u001B[38;5;66;03m# build DAG\u001B[39;00m\n\u001B[1;32m     72\u001B[0m     graph \u001B[38;5;241m=\u001B[39m collections\u001B[38;5;241m.\u001B[39mdefaultdict(\u001B[38;5;28mlist\u001B[39m)\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/project02numpy/lib/python3.9/site-packages/jieba/__init__.py:486\u001B[0m, in \u001B[0;36mTokenizer.tokenize\u001B[0;34m(self, unicode_sentence, mode, HMM)\u001B[0m\n\u001B[1;32m    477\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    478\u001B[0m \u001B[38;5;124;03mTokenize a sentence and yields tuples of (word, start, end)\u001B[39;00m\n\u001B[1;32m    479\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    483\u001B[0m \u001B[38;5;124;03m    - HMM: whether to use the Hidden Markov Model.\u001B[39;00m\n\u001B[1;32m    484\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    485\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(unicode_sentence, text_type):\n\u001B[0;32m--> 486\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mjieba: the input parameter should be unicode.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    487\u001B[0m start \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m    488\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m mode \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdefault\u001B[39m\u001B[38;5;124m'\u001B[39m:\n",
      "\u001B[0;31mValueError\u001B[0m: jieba: the input parameter should be unicode."
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    cls = Classifier(\"resources/model/classification_model\")\n",
    "    res = cls.predict_text('输入一句评论', top_n=3)\n",
    "    print(res)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}